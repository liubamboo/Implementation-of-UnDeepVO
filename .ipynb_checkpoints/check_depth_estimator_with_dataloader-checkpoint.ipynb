{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer,Conv2D\n",
    "from nets.dep_network import depth_estimation\n",
    "from losses import *\n",
    "#from utils import \n",
    "import os\n",
    "from data_loader import data_loader_with_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=.001)\n",
    "@tf.function\n",
    "def train_step(image_left,image_right):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        \n",
    "        dcx7_right,dep_right = de(image_right)\n",
    "        dcx7_left,dep_left = de(image_left)\n",
    "        #left_image = tf.slice(image_left,[0,0,0,0],[-1,-1,-1,3])\n",
    "        #right_image = tf.slice(image_right,[0,0,0,0],[-1,-1,-1,3])\n",
    "        loss_depth = dept_est_loss(dep_left,dep_right,image_left,image_right)\n",
    "        \n",
    "    gradients_de = tape.gradient(loss_depth, de.trainable_variables)\n",
    "\n",
    "    \n",
    "    optimizer.apply_gradients(zip(gradients_de, de.trainable_variables))\n",
    "    \n",
    "    return loss_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs :  0\n",
      "loss depth 0.48376474\n",
      "epochs :  1\n",
      "loss depth 0.4837647\n",
      "epochs :  2\n",
      "loss depth 0.4837647\n",
      "epochs :  3\n",
      "loss depth 0.4837647\n",
      "epochs :  4\n",
      "loss depth 0.48376474\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "train_ds = []\n",
    "##parameters for training data\n",
    "path_dir = \"/home/roboticist/Documents/Swaayatt/swaayatt_optical_flow/dataset_undeepVO/data_scene_flow(1)/training\"\n",
    "left_img_dir = path_dir+\"/image_2/\"\n",
    "right_img_dir = path_dir+\"/image_3/\"\n",
    "img_width = 416\n",
    "img_height = 128\n",
    "\n",
    "train_ds = data_loader_with_batch(left_img_dir,right_img_dir,img_width,img_height,batch=2,number_of_data=50)\n",
    "\n",
    "#de = depth_estimation()\n",
    "for epoch in range(EPOCHS):\n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    for images_left,images_right in train_ds:\n",
    "        ld = train_step(images_left,images_right)\n",
    "        #print(images_left.shape)\n",
    "    print(\"epochs : \",epoch)\n",
    "    print(\"loss depth\",ld.numpy())\n",
    "    #print(\"loss pose\",lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import generate_image_left,generate_image_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_left,image_right = train_ds[0]\n",
    "dcx7_right,dep_right = de(image_right)\n",
    "dcx7_left,dep_left = de(image_left)\n",
    "left_image = tf.slice(image_left,[0,0,0,0],[-1,-1,-1,3])\n",
    "right_image = tf.slice(image_right,[0,0,0,0],[-1,-1,-1,3])\n",
    "dep_right = dep_right[:,:,:,0]\n",
    "height = dep_right.shape[1]\n",
    "width = dep_right.shape[2]\n",
    "dep_right = tf.reshape(dep_right,[2,height,width,1])\n",
    "pred_left = generate_image_left(right_image,dep_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_left = tf.slice(pred_left,[0,0,0,0],[1,-1,-1,-1])\n",
    "pred_left = pred_left.numpy().reshape(128,416,3)\n",
    "#dep_right\n",
    "print(pred_left.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_left = pred_left.astype(np.float32)\n",
    "#l_image = tf.squeeze(left_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('pred_left',pred_left)#.numpy())\n",
    "#cv2.imshow('left',l_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(right_image.shape)\n",
    "print(image_left.shape)\n",
    "print(dep_right.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images = right_image#np.ones((2,200,100,3))*255#.reshape(1,100,100,3)\n",
    "x_offset = dep_right#np.ones((2,200,100,1))*1\n",
    "#with tf.variable_scope('r'):\n",
    "_num_batch    = np.shape(input_images)[0]\n",
    "_height       = np.shape(input_images)[1]\n",
    "_width        = np.shape(input_images)[2]\n",
    "_num_channels = np.shape(input_images)[3]\n",
    "\n",
    "_height_f = float(_height)\n",
    "_width_f  = float(_width)\n",
    "\n",
    "_wrap_mode = 'border'\n",
    "\n",
    "#with tf.variable_scope('transform'):\n",
    "# grid of (x_t, y_t, 1), eq (1) in ref [1]\n",
    "x_t, y_t = np.meshgrid(np.linspace(0.0,   _width_f - 1.0,  _width),\n",
    "                       np.linspace(0.0 , _height_f - 1.0 , _height))\n",
    "#print('y_t_1',y_t)\n",
    "#print('shape of x_t_1',x_t.shape)\n",
    "#print('x_t_1',x_t)\n",
    "#print('shape of y_t_1',y_t.shape)\n",
    "#print(x_t)\n",
    "x_t_flat = np.reshape(x_t, (1, -1))\n",
    "y_t_flat = np.reshape(y_t, (1, -1))\n",
    "\n",
    "#print('')\n",
    "#print('')\n",
    "#print('x_t_flat',x_t_flat)\n",
    "#print('shape of x_t_flat',x_t_flat.shape)\n",
    "#print('y_t_flat',y_t_flat)\n",
    "#print('shape of y_t_flat',y_t_flat.shape)\n",
    "#print(x_t)\n",
    "#print(np.linspace(0.0,100-1,100))\n",
    "\n",
    "x_t_flat = np.tile(x_t_flat, np.stack([_num_batch, 1]))\n",
    "y_t_flat = np.tile(y_t_flat, np.stack([_num_batch, 1]))\n",
    "\n",
    "#print(x_t_flat)\n",
    "\n",
    "x_t_flat = np.reshape(x_t_flat, [-1])\n",
    "y_t_flat = np.reshape(y_t_flat, [-1])\n",
    "\n",
    "#print(x_t_flat.shape)\n",
    "x_t_flat = x_t_flat+np.reshape(x_offset,[-1])*_width_f\n",
    "#print('pixel_disparity',x_t_flat)\n",
    "#print('y_t_2',y_t_flat)\n",
    "#x_t_flat = x_t_flat + np.reshape(x_offset, [-1]) * _width_f\n",
    "\n",
    "# handle both texture border types\n",
    "_edge_size = 0\n",
    "if _wrap_mode == 'border':\n",
    "    _edge_size = 1\n",
    "    im = np.pad(input_images, [[0, 0], [1, 1], [1, 1], [0, 0]], mode='constant')\n",
    "    x = x_t_flat + _edge_size\n",
    "    y = y_t_flat + _edge_size\n",
    "elif _wrap_mode == 'edge':\n",
    "    _edge_size = 0\n",
    "#else:\n",
    "    #return None\n",
    "\n",
    "#x = .clip_by_value(x, 0.0,  _width_f - 1 + 2 * _edge_size)\n",
    "x = np.clip(x, 0.0,  _width_f - 1 + 2 * _edge_size)\n",
    "\n",
    "x0_f = np.floor(x)\n",
    "y0_f = np.floor(y)\n",
    "\n",
    "x1_f = x0_f + 1\n",
    "\n",
    "#print('x0_f',x0_f)\n",
    "#print('x1_f',x1_f)\n",
    "\n",
    "x0 = x0_f.astype(np.int32)\n",
    "y0 = y0_f.astype(np.int32)\n",
    "x1 = tf.cast(tf.minimum(x1_f,  _width_f - 1 + 2 * _edge_size), tf.int32)\n",
    "#print('y0',y0)\n",
    "\n",
    "dim2 = (_width + 2 * _edge_size)\n",
    "dim1 = (_width + 2 * _edge_size) * (_height + 2 * _edge_size)\n",
    "#base = _repeat(\n",
    "x_repeat = np.arange(_num_batch) * dim1\n",
    "n_repeats =  _height * _width\n",
    "rep = np.tile(np.expand_dims(x_repeat, 1), [1, n_repeats])\n",
    "base = np.reshape(rep, [-1])\n",
    "#print('base',base)\n",
    "#print('rep',rep)\n",
    "#print('dim2',dim2)\n",
    "base_y0 = base + y0 * dim2#why\n",
    "#print('base_y0',base_y0)\n",
    "idx_l = base_y0 + x0\n",
    "print('idx_l',idx_l)\n",
    "idx_r = base_y0 + x1\n",
    "print('idx_r',idx_r)\n",
    "\n",
    "im_flat = np.reshape(im, np.stack([-1, _num_channels]))\n",
    "\n",
    "pix_l = tf.gather(im_flat, idx_l)\n",
    "pix_r = tf.gather(im_flat, idx_r)\n",
    "print('pix_l',pix_l)\n",
    "print('pix_r',pix_r)\n",
    "\n",
    "weight_l = np.expand_dims(x1_f - x, 1)\n",
    "weight_r = np.expand_dims(x - x0_f, 1)\n",
    "\n",
    "input_transformed = weight_l * pix_l + weight_r * pix_r\n",
    "\n",
    "#\n",
    "#input_transformed = _interpolate(input_images, x_t_flat, y_t_flat)\n",
    "\n",
    "output = tf.reshape(input_transformed, tf.stack([_num_batch, _height, _width, _num_channels]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(dep_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
